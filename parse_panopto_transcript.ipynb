{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "TRANSCRIPT_HTML_FILE = \"./data/raw_panopto/w3_l2.html\"\n",
    "OUTPUT_FILE = \"./data/transcripts/w3_l2.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRANSCRIPT_HTML_FILE, 'r') as file:\n",
    "    raw_html = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(raw_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \" \".join(\n",
    "    div.span.text\n",
    "    for div in soup.find_all(\"div\", {\"class\": \"event-text\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's is. I plug in everything here, so it should. Should all be available. Um, yeah. And I'm also going to do some homework for this time. Which you should try doing after the lecture, and then I'll put up the solutions before next week. The labs. All right, so let's let's get started. Okay. So. So yesterday, if this works, how do you go? Okay. So yesterday we were talking about, Oh, yeah, the learning outcomes. Right. Okay. Yeah, I always kind of skipped this bit, but somebody asked for this. Right. So let's let's recap. Right. So what are we doing? We're doing information extraction. So we started off with information retrieval, and then we realised that there were all kinds of things we need to do glamorisation and all of that. We extracted that information and now given some actual text content, we're trying to extract specific piece of information from that. Okay. And the way we're doing that is to actually tag our content with some linguistic information. Now, if we had this all of English just tied automatically with some linguistic content, then it'd be relatively easy to extract this all of the things that we're interested in. But that's obviously not the case. So what we're going to do is we've taken some content, we've given it to some linguists, they've tagged, tagged it with all kinds of linguistic information. And in this particular case, we're focusing in on parts of speech. So they've tagged all of this, and we're now going to using that information. We're going to learn to tag other information, other texts with the same kind of information. Right. And notice that we're using this training data slightly differently. So we're we're getting probability estimates for all of this training data as opposed to earlier where we used it as actual training data. And we're going to also do that going forward in the sense that when we start doing machine learning based NLP, which is in a couple of weeks, we're going to start typically learning these these priors automatically using your neural network. Okay? So that's the kind of combination of what we're looking at. And then we look at chunking and passing next week, which is kind of important in terms of a different way of structuring things. So we've looked at all of this and you're all experts in all of this. So we're going to focus in on parts of speech tagging with what are called hidden Markov models. Right. And like I said yesterday, items are quite important right across the board, all the way up to deep neural models. Now, we're going to also be kind of looking at. Okay. So just to quickly recap, right? So this is what we were looking at. We were looking at a mark off model for language. So what do we have here? So what we have is an initial set of probability distributions across all possible states that we could be in. And these states are typically words, right? And notice that as we go forward, that's going to become not words, but it's going to become what's it going to be? Because we need a prop, whatever we're going to tag. What do we want to tag? Yeah, now exactly right. So noun adverbs and all of that is what this probability distribution is going to be. So to start with, we have this we have transition probabilities. So it's going to tell us what this loop is. And this is kind of important to remember. So we're going to we're going to switch back to what this looks like. Okay. So I went through with this yesterday, and at some point I said we were finding the maximum, the most likely output of this. It turns out I was wrong. What we're doing is finding the probability of just this right, because maximally, if you count it out, you'll see that there is I think timing uniformly is maximum according to this, which is weird. So because you'll know that that those numbers are made up. So if those numbers were real numbers, you wouldn't first of all, they would be much smaller. And secondly, you would see that charmingly uniformity is probably less likely than uniformly charming. Okay. But anyway, the point is that you should be able to come up with a probability of a sequence given this information. Okay. So so far, I think we should be we should be good with that. Okay. So now we moved into hidden Markov models, and this is really the heart of everything we're looking at. So the the understanding here is that underlying language or the generation of language is an engine that is driven by things like power of speech and so on. And D and in this engine, which is parts of speech engine, you move from state to state, you go from noun to work to objective and all of that. And as you do this based on what you want to communicate, you start omitting words. Okay? It's that's, that's the underlying assumption. And of course, that's a linguistic assumption, right? Because linguists believe that we go from this underlying language engine and some believe that we are born with it. Right. And somebody. We develop it. But the point is that this kind of engine chokes out words as we move through what we want to communicate. And that is really the heart of this. To heal the mapping is that you have weather and you can move through weather for whatever reason. And as you are on a particular day with a particular kind of weather, what are you going to do is you're going to check out some associated number of ice creams that are consumed on that day. That's the way to kind of think about it. Okay. So and the way that kind of maps to words is what I just described, which is this which is your underlying engine. And you're going to move from one of these to the other as you move through based on what you want to communicate and what has come before. You're going to check out some words now that the generation is that way, but you're going to want to calculate it going backwards. And that is the crux of what we're looking at. Okay. So just a summary of that. The goal is we have observations and we want to come up with this. We have transition probabilities across this. We also have transition probabilities here. We can do that. Okay. But we're not going to worry about that for now. But when we look at deep neural models, you will see that what we are actually going to do is we're going to use these transition probabilities and that's it, right? And it turns out that that can do quite a bit for you. Okay. So just to quickly recall, Markov model is a state machine that looks like so you have states as 12s and you have transition probabilities, A1 one, E, one two, which means state 1 to 1, state 1 to 2, 1 to 3 and so on. And those will sum up to one. And you need to know why, because that means every there's there's always the chance you'll go somewhere. There's never a chance that you'll go elsewhere to some other state you don't know. Right. And that's why that will come up to one. And your initial probabilities add up to one, which means you will start in one of the states that you're aware of. You're not going to be at least somebody else. All right. So, so far, so reasonable. Okay. And again, to recollect, here's our hidden Markov model. We have observations All one, two, T you have these are the states, these are the emissions. You have transitions and you're going to given the observations, we're going to calculate the states. Okay? So that is the crux of what we're looking at. And so today we are going to try to figure out how to do that. Okay. So hidden observed and this is part a speech example, hidden and observe. Okay. So they should we should be very clear on your head. Right. What is observed is the words and what is hidden is the parts of speech. Even though when we started off, we were we had a kind of Markov model with words going to each other. That's not what we're looking at. We're looking at this, which is the hidden mock of model. Okay, so what are the components? Let's look at what goes into creating this Markov model. Okay, So the first order states and the states are here. These are the states associated with what we're actually calculating. And remember that in this particular case, it is just these. Okay. And so, of course, you can have a whole host of other things. And what I want you to remember is how this will become really big, really quickly. Right? So you don't actually need to know any actual parts of speech except for probably these three. Okay. But you can you can imagine that adverbs, adjectives and so on and so forth. Right. So there's several of those that would fit in there. So remember, the transitions are like so and like I said, we're going to use this to represent those transitions. Okay? So what we're going to have is we're going to have a verb and notice you have a probability of going from a verb to a verb, okay? Which means it's not actually given here, but it's a it's a loop, like so. Okay, so it's a loop allowing you to kind of do that. And the probability of here is if I'm at a verb, I'm out here. What is the probability of going from here to here? Right? So so far that's everything clear. Right. And of course, what would this what would this represent? Can anyone tell me from these like that one. Yeah. Yeah. Right. Yeah, exactly. I'd say if you're already in the noun state, what is the probability of getting the next one? Could also be enough. Right? So if we drew this out as a state machine, you would have kind of a loop there. And that is what is associated with that value. Okay. So like I said, yes, yesterday, you should be able to kind of go between these. And here you have the initial probabilities. So can someone tell me which of these which of these six states are likely to have the highest probability, the highest initial probability based on assuming that this is what we eventually come up with? Right. Which of these will have the highest initial probability? Yeah, The first. We're going left. Right. So, uh, so the initial one will be the very. So let's go back here. So what we're seeing is this is actually maybe this is the better. Are they? Yeah. Okay, so you have back the bill. And so notice that this is associated with the first one. This is associated with the second one. And this with the third. Right. So which of these three do you think will be the the highest initial probability? I know the for this phrase, but. Well, the the stock, the stock of your face. So the what is the first word in this place back. So so what if you started it off and you wanted to kind of generate the token for the first one, you're going to assume that your initial value of buy will spread out the probabilities across this in such a way that it's going to land on this. Right. Does that make sense? Right. Right. Yeah. Yes. Yes. Yes. Yeah. Yeah. Oh, I see what you thought it was in general. Yeah. Okay. I see what you mean. Yeah, yeah, yeah. So in, in this specific. I should have made that clear. Yeah. Okay. In this specific example, it would be the probability distribution based on whatever else is happening would kind of give you initial value. That's actually a very good point. Right. So you should know that the the PI that we looked at, which we we saw, okay, I'll come back to that. But the pi that we look at is going to give you a probability distribution over this. And they're always basing all of this information on the observations. Okay. And that's, that's yeah, I should have made that very clear. Yeah. So for the work that. She. That's that's a good point. So the question was, are we assuming there's more woods down here or are we going to just look at this and just assume that back has the most probability? Right. And like you pointed out, when we just start, back is unlikely to have the most probability. But given these three observations, it might have the highest initial probability. So it's a combination of the both the things that you said, which is it could be and they could be something else here which is telling us that this now has the highest probability. That's one way to do it. The other way to do it is, given all the words that I have in my sequence, what is the highest initial probability? Right. And also, as we go through this, we'll see that we don't really have to define our initial probabilities separately. It's all going to be part of our algorithm, which will simultaneously give us the maximum probabilities at each state. Okay. Okay. Uh, right. Where were we? Was this it? Yeah. Okay, so we've looked at this. This is where we are. And so what we're going to do is and, and this is just to kind of emphasise that point, this is this phrase starts with a word, right? So it's not and that should have been clear in my slides, which it isn't, that this is not just generally you will start with above. Okay. So that that's something worth remembering. Okay. Okay. So what is the next set of things we're going to do? So, so remember, we have this is our hidden kind of states and we're going to transition between them. We have associated observations and our observations in this case are back the bell and it's also going to give us emission, right? So what is that? It is, given that I'm in this state, in the state machine, what is the probability that I will generate this particular verb? Okay. And that is the that is what's called the emission probability. And this is called an emission because like I said earlier, the assumption is that you have like an underlying engine which is going to have different states going to check out different words. Okay, So you're out at a particular state. You reach there by moving through a bunch of things. And when you are there, what are you going to do is you're going to start checking out words and what is the probability that the things that you check out of this particular sequence? Okay. So we're going to first look at how to calculate each of these things, and then we're going to see how to put that together to actually generate what this is. And we're going to do that in two different ways. One is brute force and the other is more kind of in A more optimised B, okay, so here's the emission probabilities. So you have here, what is the probability that you're going to chuck out a back given that you're at this position one, right. And if you will, at a verb, what is the probability of chucking out a dog? What do you think this probability is going to be? And he talks the probability that when your your. Yeah. Yeah. It's zero. Right. There's so there's no sentence in which you can generate or generate the which takes on the form of a verb like is there. No I can't think of one. I it's probably not that. Okay. So we're going to make two important assumptions, right. They're important because in language you'll see that they kind of nearly always work. But we'll also see that they don't work and we look at when they don't work. So what are we going to do is we're going to assume that what is required in calculating this particular state, the one there is just the one before it, Right? So the only information that we require to calculate that is associated with the state we had before it and nothing before then. Okay. So we're saying if I want to generate the problem, if I want to find the probability distribution of what this is across all possible outcomes, all I need to do is look at the previous one. So how do you read that off? The way you read it is what is the probability of State II being something given? States is one the fourth state you have a self all the way up to state II minus one, which is just the one to fly. Okay, So given that this is the sequence that you have, what is the probability of this being a particular part of speech in this case? What is the probability of being B? Now you can also see the property being a verb and so on and so forth. Okay, So that's how you read that out. And what we're saying is we're making the simplifying assumption. That the only thing that this is kind of needs to depend on is the one before it. Now, is this always the case of language? And can you think of more of an example when this isn't? Any thoughts on when can you come up with any any example really where. Yeah, just like context at the very beginning of a sentence relating to what the word means. Yeah. You're saying I'm talking to the week? Yeah. I'm going on a trip with English. Yeah. Yeah. So that's a good point. So. So remember that it may not be the word itself. It may be the entire context that provides you with what that is. Right. So the context of where we are could change what's happening in that particular case. And coming up with the examples for this is slightly harder than I thought it might be. Any other examples that you can come up with? Okay. So literally the pine cone one, right? So you look at pine cone with this ice cream cone. And obviously, I'm sure you can change that sentence to something, which is, you know, I was climbing a tree and a cone fell on my head or whatever is what you're suggesting, which is the context. Right. As opposed to it was a warm day and I was eating ice cream out of a cone. I was eating ice cream out of a cone. Still contextualises cone. But I didn't say ice cream cone. Right. And it's but it still means ice cream cone. And therefore, this is this is not always a good assumption. Okay. And you'll notice the way we offset this when we go into large language models is to have self attention that will be spread across all of the context that you provide. And you'll also see how that becomes exponentially complex. And therefore, we had to wait for computational power to catch up to be able to actually track all of that. Okay. But at this stage, what we're going to do is we're going to limit ourselves to the one word before it. We're also going to make that independent assumption, which is can someone try and guess what that might be based on the slide alone? What is this? Yeah. So you had something like, um, I don't know, a long name that I was like, middle name or something. And you were assuming the last name was an independent on that was before? Yeah. As long as not your assuming doesn't have any kind of bearing. Kind of. Yeah. Yeah, exactly. Yeah, that's exactly right. So. So you're assuming and the last bit is, is is, is the part to kind of focus in on. Right. Which is so we're looking at the emissions. Okay. So given that I'm here, what is the probability? And of course, like you said, you could have this dependent on a whole host of things before here. Okay. And all of that together would tell you what would your emit. Right. But you're going to assume that your emission of what the word you're going to generate is focussed solely on the current stage. Okay. Does that does that make sense to everyone? Right. Was that a had No. Mike, I guess you can scratch your head here, but. Yeah. Okay. So, so that's that's that's kind of some another simplifying assumption. And this is obviously not true. Right. Because notice that like you pointed out, if the previous one was a noun, then what's going to happen here is the chances are, if I have now, now, now, it's actually a what? A name possibly. Right. And and therefore, it's not going to be below. And the probability distribution is going to start changing based on what your previous states were. Did that that makes sense. That was that That was the example that was given. Right. So if I had. Now, now, now you're going to assume that that's a proper noun unless you I mean, there's some cases which I'd like Prime Minister, whatever. Right. And that's not a proper noun, even though the previous one was a noun and so on. But mostly it would be enough. Okay, so we're going to look at what this means formally. So formally you have a transition matrix eight, you have an emission matrix B So remember, the transition matrix is going to tell you what the probabilities are to go from one to the other. The emission matrix is going to tell you, given you are in a state, that given that it's a now, what is the probability of generating each word, not just bill, but it's also going to tell you what these probabilities are and you're going to use that to somehow maximise things. And it's going to also have associated with the sequence of observations, which is what I should have made me think earlier, because all of this is going to focus in on that, Right. So that kind of links what both of your questions were and what we want to do is we want to maximise the probability of these tags which are states given the observations. So we want to find the sequence of tags such that the entire sequence is maximal given the observation. So what does that mean? So if we go back here, we want to see what is the sequence that I need to come up with here that's going to have the maximum possible likelihood given these observations? Okay. And that is what that is telling us. It's saying what is the maximum? I notice the importance is sequence, right? And that is that answers your question, which is you were saying, what is the first one? Is this the first ever word? What's going on? And it's like we're like, no, no. What is the first tag that's going to be associated with it, given the observations? We're going to limit it to those observations. And that is what these observations are here, which is 1 to 1. Okay, so what do we want to do? So we want to say this is exactly what that translates to, right? So what is the probability of word determiner now given back the bill? And of course, we want to know all other possible combinations, right? What is noun, determinant, verb, verb, noun, determinant, and so on all of this and we going to list all of those out and we're going to pick the one that is has the highest probability, conditional probability, not just probability, the highest conditional probability. And that is going to be what's associated with the sequence. Okay. And this idea of sequence labelling is really important and it's going to come up in a whole host of things like somebody was talking to me about stock market trading. Right. And you'll see how sequences here can also something happen. Yeah, the sequence here also kind of extends to that, right? So this kind of underscore, you're assuming that there's an underlying market genie, as it were, which is checking out trading information, which is the prices associated with your stock. And you're saying, how can I predict what the state is is going to be good, bad, what's happening? So there's different ways in which you can use essentially what we're looking at and here we're looking at it in terms of our what? So now, obviously, this is a messy, messy one. So what we're going to do is we're we're going to have to add on. Right. So. So we're going to have to add on a second part to this. Okay. What is the second part? We're going to say, you know, this relies on dependencies of long sequences. So we want to try and find out how we can simplify this. Okay. So this is the painful math. And I think somewhere here there was something odd ago. Right. What does that mean? That means that this entire messy map, you're going to have to know. Okay. It's. It's just life. Right. Okay. Oh, it's just. What? I'm going to force you to do one of those things. Okay. So what are you going to have to do is remember, we start here and we want to try and simplify this, because this is this is painful. Right. There is no easy way of generating this. And what we're going to do is we're going to use base rule to flip this. Okay. So probability A given B can be written as probability be given a times probability A divided by probability B, that is base rule. And you can write that for all max in pretty much exactly that same way. Now, when you write this out, I will accept you just writing base rule and flipping this. Okay. You don't have to like, in any way prove what base theorem is all about. But independently, it's a good idea to know what that is because it'll help you understand a couple of things along the way. Now, I claim that you can go from here to here. Can someone tell me why? You can? Yes. You know, when it comes to every possible sequence. What? Yes, exactly. Right. So given a sequence of observations, this B, a, B, probability of w1n is going to be a constant in this one sequence that we're looking at, it's going to be it's going to be a constant because that sequence of words is going to be the same regardless of how I read all of my tags. So. Right. So if I go back here, you're going to see that this is always going to be back the bell. And I'm just juggling this around to see what the correct ordering is. Right. And that's not the focus of what we're doing. And we're saying since that's going to be a constant, the maximum of a bunch of things divided by something is going to be the same as the maximum of those bunch of things. Right. That kind of make sense. Okay. Right. So what we want to do is we want to maximise d hat, which is this one, the sequence. So you already know what the tags are, but you want the correct sequence of those. Now do you know the tags? You don't necessarily know what that what the exact tags are, but you know what the overall tag set is. Okay. And so now you come up with something that is that starting to look a little more interesting. Okay. So what what we're going to do is we're going to look at this and see what that means in terms of what we've already looked at. So what it means is the first bit, which is this is what is this? Can anyone kind of tell me what that might be? What is the probability of words given tags? That's your emission probabilities, right? So this is this is what we looked at in terms of our probability of our emissions. Okay. And the way it's written out like this is that we're going to say we're going to link it together with all the previous words that we've seen. Right. So that's why you have this extra kind of pipe. Don't worry too much about that multiplication. We'll actually see how it works in a second when I write it out. Okay. So don't worry about it. But you should be able to do the math behind it and the actual calculations. Okay. Right. So and of course, what is the next bit that we want? The next big one is that what is the probability of each sequence of tags? And what is that? That is just our transition probabilities with under the Markov assumption. Right. Like we have this Markov in simplification that we've done. And with that simplification, this is this whole. What is that simplification that at every stage I only look at the previous state. Otherwise, this won't work. I can't just do this. I have to use the entire previous sequence. However far I need it. But I'm simplifying it to this because I've made that assumption. I'm simplifying it to this again because I've made the assumption of independence, which is what we talked about earlier. In both cases, I'm able to do this only because of the simplifying assumptions. So when you write this out, you need to write out two things. One is what is this? What is that which is emission, which is the tag sequence, which is our transition probabilities. And you need to also specify the simplifying assumptions that are made to make this a reality. Okay. So to summarise, what do we have? We have we started with this. We wanted to come up with a probability, the maximal probability distribution for our tag set, the hat we want to come up with the ordering such that we maximise this and we can do that using this maximisation which is approximated to this because of our simplifying assumptions, where this is emission probabilities and this is the transition probabilities and we just keep multiplying them up. Okay, so what does this mean in practice? How do we calculate each of these things? So what we're going to do is we're going to say, you know, what is the probability of. So this is our transition. What is the probability that the current tag is a noun given the previous tag is a determinant. And the way we do this is. Yes. Yeah. Yep. If you look at that. Yes. There will be. You know, it's the. Yes. So the question was, is this the probability of Bill being a noun? Yes. It's the other way to look at it. Actually, it's it's very close to that. But it is What is? Given that I know that a noun is going to appear at this point, what is the probability that it is, Bill? Right. Because remember, we're assuming that this is going to chuck out a bill. So that is our generator and it's going to emit a word. So given that, I meant that in that state of noun, what is the probability is going to throw out a bill? Yeah, but in practice, do you get better results like states. If you like. Know. Like what? Yeah. Yeah. So that was a good question. Right. So the question was like, how good is this Markov assumption and do you get better results if you go further back? And the answer is yes, right? The thing is, you'll see very quickly that this kind of product becomes really messy. And when we actually do it, you'll see that it gets really, really messy. Okay. So, yes, that is in general the case. And large language models handle it by tracking all of it. Yeah. You had a question like that where it's a good. So that's a good question. So the question was, is there ever a case when you can make this assumption, Markov or something? I would go so far as to say that language is a good example where you really want work. I and while we're studying this for simplicity, I'm going to I'm sticking to one. But typically, most US cargoes won't stay with one. It's too it's too short a context. Like most phrases will just simply not work with that. Right. And I mean, one is like long nouns that we just looked at and you'll see that there's very often a structure that comes into being. Right. So what was. So if you said, I met a friend for lunch and okay, so, so that so the example that you, that you give is you can say I met, I met Mary for lunch and she was late. Hypothetically. Right. And what you can do is you can extend this arbitrary. You can say things like I met me for lunch and on the hot day while I was sitting out in the sun, she was late for she was late. And I can then obviously expand extend that indefinitely. Right. I can plug in more and more kind of conditionals and you'll see that we can track that. We can track that across arbitrary distances. And we do that because we keep track of the structure of the entire sentence. And you can't do that using any arbitrary length. Markov model. Right. It doesn't matter. I can do five, six, whatever, but I can always create a sentence where Mary and she are far enough out that they a single Markov assumption is not going to capture. And now it's a problem. And the way we do it is that we track the structure and we don't count the words out, right? We just only interested in how that structure breaks. And that's what we'll be looking at in the next kind of lecture to see how we can break down that, those kinds of things. Right. And the way people do this is you will see what's really exciting and cool is that large language models or even language models can track this very efficiently. So this is called, quote, utterance resolution, where, you know, you have a pronoun and you're going to assign it to a named entity, and you need to kind of keep track of that. And also other languages. You need to do it a lot more efficiently. Right? Because if you're speaking, let's say French or whatever, where you have an inflection associated with it, you need to keep track of the gender of all kinds of things. Right. And to be able to do that, you can't do it using this kind of assumption. So language actually is a good example of that. But all of this, we're trying to simplify things. Okay. So what do we have here? What we have here is we're trying to count out the probability of this being a noun given that the previous was this. And that's easy enough to do. How do we get these counts? Where do we get them from? Any thoughts? Yeah, exactly. Right. So we need that large amount of label data to be able to make these kind of inferences. Right. So you have the count of this divided by the count of all times. I just thought determiner. Right. And this is obviously made up because you will see that that those are not the kind of numbers that come up. The second thing we need is the emission probability, which is you're going to look at this and you're going to say. What is the time? What are the what is the probability of Bill given that that the bill was a now. And so the way to calculate that is you're going to say, what are the nouns, How many times, how many nouns did I have and how many of those were built. So this kind of answers your question, right? And you'll see that that is what it is. And we want to kind of combine. Okay. So we're going to put all of this together and we're going to go through actually coming up with the we're generating the correct parts of speech and we're going to do that. So you're going to this whole multiplication thingy that you saw earlier should get sorted out. Now, what just happened? I don't know. Right? Maybe I removed part of the slides that wasn't. But anyway, it should be in your notes at some point. So hopefully you'll see that that's that's okay. But essentially what I was going to give you. Was I right? That's it. Okay. I'm going to come back to that. I think what I was going to give you was this right. This is what you're going to see. Okay. Now, I know what that looks like. Yeah. So all you're going to see is this is what it looks like. You will see that these are transition probabilities and these are emission probabilities. So that is Bob. You know what it is? What is the probability that was fish given, Verb fish given now. So I'm in this state. What is the probability of emission? So this is what your emission and your transition probabilities look like. Okay. So just to quickly go over this before we start stepping through it, you have hidden state observations and remember that we now need to come up with every possible sequence of this, which is going to be a pain. Okay. So just just if you look at this, what we're going to do is we're going to say, I have stock and I have a probability distribution over all of my initial states. That's what that looks like. And given each of those states, there's going to be an emission probability associated with each of which with my observation, which luckily is just one. So Ms. If it was Bob, that was it. And we know that this is the combination, so I'm going to have to multiply those two things here and then I have to continue doing that all the way across. I have to have this plus this, times this. And if this was the previous state, plus this times, this and so on, and then I have to find the maximum sequence that is the brute force way of doing this. Okay. And but the algorithm tells us that we can make some, you know, simplifying assumptions. And actually, I think the best way to do it is to literally just do it and see what that looks like. So let's see. See, I can get the visualiser to work. Okay. Right. So can can everyone can you guys see that one? You can see it. Can you see it? Yeah. You're okay. Okay, great. So what we're going to do is I'm going to have to try and see how. Right. Okay. So we have we have we can fish. Okay, so we're going to work on I can see myself that. That's good. Okay, so we have. We have the stock and we have. So let me just pull this out so that I can actually see what I'm doing. Okay, so what do we want to do? What we want to do is we want to come up with. The initial states. So I'm going to write down what the initial states were so it can be verb, noun, pronoun, auxiliary and finish. I did. I tried everything in a way. You can see how you can. Okay, very good. So now I'm going to just have my initial state. So what is my initial state? So I'm going to come in from my start state and I want to see what the first one is. So what is the first probability the first probabilities are associated with. With what's over here? Okay. So what is it that I can start with? I can start with one of these. One of these things. So what is the initial probability of it being a verb? I have 0.01. Okay. And the probability of it being a noun is 0.10. And I'm going to write out, okay, I'm going to write this out as well as 0.600.29, and there's no chance that I'm going to finish. Right. So that is my probability distribution over those kind of initial states. Now, if I were a verb, if the initial state was a verb, what is the emission probability of what do we have? It was V, right? So it was V. What is the mission probability? And I have to write this out here. Right. So if I was a you can see that. So. So this one, you can't see that either. Okay. So the point is, if I was a verb, what is the mission probability for we? And you can see can somebody that out for me. Yeah. Okay. And what would I have here? But. So basically, this is unknown. Okay. So if. Yeah. So it's basically the column bite. It's the it's the entire column, Right. And the pronoun is one. And the auxiliary there is zero. Okay. And of course, when I'm finished, I'm not going to omit anything. And that's why there's no associated value here. Okay. So this is what I have. And so notice what this means is because it's a multiplication. Yes. You had a question. So the problem is. Yes. A noun. If the we given. It's a pronoun, it's a we. And given it's auxiliary, it's a weak. Right. And of course these are made up. Okay. So that that's just because multiplying this stuff is already going to be a nightmare. So it's likely made up. Okay, So now what we're going to do is we're going to start writing out the total here. Okay. And you'll see immediately this is a pain because it's going to be zero zero. Is that it? How many zeros do I put in there? One more thing. Thank you. Right. Okay. And. And you similarly multiply out all of these things. Okay. And so that is just the first step. Right. And now the second step is where it gets really annoying. The second step is I'm going to say the previous one. Let's assume that it was a verb. Let's assume that the previous one was above. Now I'm going to have to calculate what the transition probabilities were. If I was actually here. If I was actually here. What is the transition probabilities? Right. What is the transition probabilities associated with each of them? And that is just a row. So I'm just going to quickly write that there. This is 0.02 and this is 0.63. This is 0.07 and 0.13. Which course that is. Right. So if I had, the previous state was a verb. This one is going to be this being a verb is this noun, is this pronoun, is this auxiliary this and finishes what is finished? 0.0515. Okay. Does that make sense? So that's how you come up here right now. The second thing to do is you have to now come up with emission probabilities of we can. So you have can. And now you go through the column associated with can and then you write out these probabilities which are 0.10 and so on, and then you multiply them out. Okay. And now here's where here's what we need to actually be doing. What we need to do is this is just one we need to do this one noun as well. Right. And then we need to do it for auxiliary and then we need to do it for finish. So we need to go through this entire thing. And that is the brute force way of doing. And how do I combine this and this? I have to multiply that out, which is what that pie was in your multiplication. Right. Did that make sense to everyone? Right. So what I have to say is the first one was a verb, and the second one was a verb. So I have to take this one and I have to multiply it out with that one. Right. And then, of course, I have to come up with a similar kind of a list for nouns, which I can do by reading off that way and that way. And then I have to multiply those things up. Okay. And this is the entire thing. I can't actually take the maximum at every any one step, because what could happen is further down the line, I could get a much larger number or a much smaller number, which will ruin that entire part. Right. So I can't. It's like a means, right? I can't say I'm going to take the shortest left because down the line it could be a dead end. Right. And that's literally what could happen here. So we need to come up with the maximum probability of the enquiry, as it were. Okay. And this is called this is done using been taught in large language models. And here what we're going to do is we're going to use the word algorithm. The brute force is what I just told you. The for a particular word in this case can you're going to have verb, you're going to have noun, and you're going to have all of these going down. Okay. And what I can do here for the first time is I can make a simplifying assumption. I can say, let's take this right. The the result of this product, right of this, times this. And I get something, something. And what I can say is that in this case, I can take the minimum. I don't have to consider all of them. I can take just the minimum because that is just the maximum Y, because anything smaller multiplied by the same thing on the right is anybody going to be smart? So the way to visualise that is to go back here to this one. What we're saying is, let's say I'm here, what I'm doing is four can I'm going through all of these different things that are coming in to auxiliary, all the different rules that are coming in here is what I'm finding. And I'm saying, Hey, I can check out everything that is non maximal up to this point because if it isn't maximum here, then I multiply it forward. The smaller numbers are never going to be smaller. Right. And and I know it's not easy to visualise. The only way to do it is to literally write that out. Which is why I've given you two different ways of writing that out. When you write it out, you would see essentially what what this entire algorithm is doing is saying, If I'm here and there's like three different ways to get here, anything I multiply forward, I'm going to do exactly the same thing with all three numbers. And if I have a smaller number, multiplying that smaller number by something will be smaller, then multiplying with the larger number. So I'm just going to take the largest of these things. Okay. So what is this? There's a subtle difference, right? There's a subtle difference. What is the difference between taking the maximum across all of this and taking a maximum at a single node? Well, the maximum across all. All of this is that going forward it could maximise unless it's a zero going forward some way, it could be much higher. That cannot happen for the same note and notice in the first instance. We don't have that right. We just we have only one kind of part. But here, if you have two different parts to reach the same place, it makes sense to take the best of those parts because anywhere else you go, you still have to get there. And therefore the best way of getting there is still the best way of going forward from that. Yeah. So if you're happy with that, yeah, you still have a valid maximum up to now about it, but you can talk to them about it. Might be possible to throw it out as well. Yeah. And the only reason we can just go down to one single top. I see what you're saying. So. But we're not doing this across all of these. We're saying we're doing it only across auxiliary. So there will be a park, there'll be multiple parks into auxiliary, and from there there's multiple parts going forward. All I'm saying is you can't find the maximum part across nodes, but within the node you can find the maximal part and keep that as the best part. And then you you still have to go to every other node going forward. But we would still need to find the maximum possible know across them. Yes. Yes. So within the node. So if you go back here, what did we have? We had one of this. So we had Rob and out here you had Well, and notice that this is just it's splitting of this one part. So this is the part is verb to verb. And now you have four different things here. Right. Because that's literally what this is. So if the first one was, well, what the the second one being verb, it's all these four things. So that's what this kind of looks like, right? What I'm saying is you can crush this down to just one. What you cannot do is going from verb to verb, noun, and whatever. You can't crush these across different nodes within a single node. You can you can simplify it. And that is the crux of the word. So, I mean, it's a messy thing to remember, but what I'm going to do is I'm going to ask you to work through this. I'm going to give you a link to a YouTube video, which I think is useful. And I'm also going to give you some homework to kind of go through this. Okay. Also next week, the labs, which will be two days, what we're going to do is it's going to be very short in terms of the actual lab work. So what you're expected to do, though, is to do this homework during that time. And I'll be there. So if you get stuck with actually solving this, then you can ask me. Okay. But what you'll be doing for the labs is you'll just be using some automated kind of PA speech data to see how quickly you can do it. And that's it. Okay. Right. So the best thing to do, I think, is before that lab, which is next week. So you have a whole week to do it. If you can just spend some time, try working out the example that's in the handout, that'd be super useful, right? So that it'll kind of clear things outfit, then It's really simple after that. I mean, all of the what I get them saying is if I have a bunch of numbers and I'm going to multiply it with another bunch of numbers, then the smallest, the biggest number here will always give me the biggest product. Right? And that's that's it. It's not it's that's all it is doing. All right. So if you remember that, that's pretty much all you need to know, right? And that brings us to the end of sequence labelling, at least in this case. We do sequence labelling using language models in week five or six or whatever, whenever after your break. Okay. So I'll see you. I'll see you in the labs.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the transcript to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    f.write(transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
